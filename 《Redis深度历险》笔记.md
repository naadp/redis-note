有幸拜读钱先生《Redis 深度历险》，收获颇多，简要做一下笔记。

应用篇——消息队列/延时队列

我们平时习惯于使用 Rabbitmq 和 Kafka 作为消息队列中间件，来给应用程序之间增加 异步消息传递功能。这两个中间件都是专业的消息队列中间件，特性之多超出了大多数人的理 解能力。 使用过 Rabbitmq 的同学知道它使用起来有多复杂，发消息之前要创建 Exchange，再创 建 Queue，还要将 Queue 和 Exchange 通过某种规则绑定起来，发消息的时候要指定 routingkey，还要控制头部信息。消费者在消费消息之前也要进行上面一系列的繁琐过程。但是绝大 多数情况下，虽然我们的消息队列只有一组消费者，但还是需要经历上面这些繁琐的过程。 有了 Redis，它就可以让我们解脱出来，对于那些只有一组消费者的消息队列，使用 Redis 就可以非常轻松的搞定。Redis 的消息队列不是专业的消息队列，它没有非常多的高级特性， 没有 ack 保证，如果对消息的可靠性有着极致的追求，那么它就不适合使用。

Redis 的 list(列表) 数据结构常用来作为异步消息队列使用，使用rpush/lpush操作入队列， 使用 lpop 和 rpop 来出队列

队列空了怎么办：

* 空轮询：循环不停的 pop.
  * 影响
    * 这是浪费生命的空轮询。空轮询不但拉高了客户端的 CPU，redis 的 QPS 也 会被拉高，如果这样空轮询的客户端有几十来个，Redis 的慢查询可能会显著增多
* sleep：休眠一会儿，再去获取。
  * 影响
    * 睡眠会导致消息的延迟增大。 如果只有 1 个消费者，那么这个延迟就是 1s。如果有多个消费者，这个延迟会有所下降，因 为每个消费者的睡觉时间是岔开来的
* 答案： blpop/brpop
  * 这两个指令的前缀字符 b 代表的是 blocking，也就是阻塞读。 阻塞读在队列没有数据的时候，会立即进入休眠状态，一旦数据到来，则立刻醒过来。消 息的延迟几乎为零。用 blpop/brpop 替代前面的 lpop/rpop
  * 影响
    * 空闲连接的问题。 如果线程一直阻塞在哪里，Redis 的客户端连接就成了闲置连接，闲置过久，服务器一般 会主动断开连接，减少闲置资源占用。这个时候 blpop/brpop 会抛出异常来。 所以编写客户端消费者的时候要小心，注意捕获异常，还要重试。

延时队列的实现: 延时队列可以通过 Redis 的 zset(有序列表) 来实现。我们将消息序列化成一个字符串作 为 zset 的 value，这个消息的到期处理时间作为 score，然后用多个线程轮询 zset 获取到期 的任务进行处理，多个线程是为了保障可用性，万一挂了一个线程还有其它线程可以继续处 理。因为有多个线程，所以需要考虑并发争抢任务，确保任务不能被多次执行。 Redis 的 zrem 方法是多线程多进程争抢任务的关键，它的返回值决定了当前实例有没有抢到任务， 因为 loop 方法可能会被多个线程、多个进程调用，同一个任务可能会被多个进程线程抢到，通过 zrem 来决定唯一的属主。 同时，我们要注意一定要对 handle\_msg 进行异常捕获，避免因为个别任务处理问题导致循环异常退出.

应用篇——位图（详情可以看小灰的笔记）

使用场景：

* 一个用户的签到记录: 今天签到了, 就是1; 没签到, 就是0.
* 小灰说的那种场景: 标签的存储、标签的交集、并集.

注意啊: 它里面只有0和1.

短板: 小灰说的取反、以及分散不均的问题.

Redis 的位数组是自动扩展，如果设置了某个偏移位置超出了现有的内容范围，就会自 动将位数组进行零扩充

命令: setbit(setbit s 1 1: 将s的第一位设为1)、getbit(getbit w 1: 获取w的第一位的值).

应用篇——HyperLogLog

* 场景: 统计每个页面，在一天之内，有多少个用户访问了。注意啊：同一个用户的多次访问，只能算一个。因为你统计的是多少个用户访问，又不是说统计总次数。
* 简单的方案，那就是为每一个页面一个独立的 set 集合来存储所 有当天访问过此页面的用户 ID。当一个请求过来时，我们使用 sadd 将用户 ID 塞进去就可 以了。通过 scard 可以取出这个集合的大小，这个数字就是这个页面的 UV 数据。没错，这是一个非常简单的方案。
  * 问题：但是，如果你的页面访问量非常大，比如一个爆款页面几千万的 UV，你需要一个很大 的 set 集合来统计，这就非常浪费空间。如果这样的页面很多，那所需要的存储空间是惊人 的。为这样一个去重功能就耗费这样多的存储空间，值得么？其实老板需要的数据又不需要 太精确，105w 和 106w 这两个数字对于老板们来说并没有多大区别，
* 答案：Redis 提供了 HyperLogLog 数据结构就是用来解决 这种统计问题的。HyperLogLog 提供不精确的去重计数方案，虽然不精确但是也不是非常不 精确，标准误差是 0.81%
  * 尧哥说明: 它是去重计数的. 你可以理解为一个大的而且计数不精确的Set.
* 它只能三个功能:
  * 添加: pfadd——添加时是去重了的. 和set的sadd命令一样.
  * 计数: pfcount——查看总个数. 和set的scard命令一样.
  * 计数合并: pfmerge——将多个 HyperLogLog的pfcount的值累加在一起. 注意: 累加的时候也是进行了去重的.
    * 场景: 产品经理说, 有两个页面, 它俩很相似, 你就把这两个页面每天有多少个用户进行访问的值, 合并到一起吧. pfmerge可以干这个.
  * 注意: 它不提供获取元素和判断元素在不在里面这么个功能的(是否存在需要布隆过滤器).

HyperLogLog 数据结构是 Redis 的高级数据结构，它非常有用，但是令人感到意外的 是，使用过它的人非常少

* 深入使用场景:
  * 它需要占据 一定 12k 的存储空间，所以它不适合统计单个用户相关的数据。
  * 如果你的用户上亿，可以算 算，这个空间成本是非常惊人的。但是相比 set 存储方案，HyperLogLog 所使用的空间那真 是可以使用千斤对比四两来形容了
  * 不过你也不必过于担心，因为 Redis 对 HyperLogLog 的存储进行了优化，在计数比较 小时，它的存储空间采用稀疏矩阵存储，空间占用很小，仅仅在计数慢慢变大，稀疏矩阵占用空间渐渐超过了阈值时才会一次性转变成稠密矩阵，才会占用 12k 的空间
* pf 的内存占用为什么是 12k
  * 过在 Redis 的 HyperLogLog 实现中用到的是 16384 个桶，也就是 2^14，每个桶的 maxbits 需要 6 个 bits 来存储，最 大可以表示 maxbits=63，于是总共占用内存就是 2^14 \* 6 / 8 = 12k 字节。

应用篇——布隆过滤器

顾名思义: 从名字可以看出它的作用——过滤、去重

注意啊: 布隆过滤器 和 位图 是两种数据结构. 只不过布隆过滤器使用到了位图而已.

* 区别
  * 使用 HyperLogLog 数据结构来进行估数，它非常有价值，可以解决 很多精确度不高的统计需求。 但是如果我们想知道某一个值是不是已经在 HyperLogLog 结构里面了，它就无能为力 了，它只提供了 pfadd 和 pfcount 方法，没有提供 pfcontains 这种方法

场景: 

* 我们在使用新闻客户端看新闻时，它会给我们不停地推荐新的内容，它每次推荐时要去重，去掉那些已经看过的内容。问题来了，新闻客户端推荐系统如何实现推送去重的?
  * 如果历史记录存储在关系数据库里，去重就需要频繁地对数据库进行 exists 查询，当系统并发量很高时，数据库是很难扛住压力的
  * 你可能又想到了缓存，但是如此多的历史记录全部缓存起来，那得浪费多大存储空间 啊？而且这个存储空间是随着时间线性增长，你撑得住一个月，你能撑得住几年么
* 主角来了: 布隆过滤器可以理解为一个不怎么精确的 set 结构，当你使用它的 contains 方法判断某 个对象是否存在时，它可能会误判
  * 当它说不存在时，那就肯定不存在
  * 当布隆过滤器说某个值存在时，这个值可能不存在；
* 使用:
  * 添加元素: bf.add——类似于set集合的sadd
  * 查询元素是否存在: bf.exists——类似于set集合的sismember
* 注意事项
  * 布隆过滤器的 initial\_size(初始化长度) 估计的过大，会浪费存储空间，估计的过小，就会影响准确 率，用户在使用之前一定要尽可能地精确估计好元素数量，还需要加上一定的冗余空间以避 免实际元素可能会意外高出估计值很多
* 原理
  * 每个布隆过滤器对应到 Redis 的数据结构里面就是: 一个大型的位数组和几个不一样的无偏 hash 函数。所谓无偏就是能够把元素的 hash 值算得比较均匀
* 其他的使用场景
  * 爬虫时对URL去重: 大幅度降低去重存储消耗, 但是也可能会让你爬虫系统错过少量的页面.
  * 黑名单: 例如IP黑名单、用户黑名单(但是自己的区块链的那个, 并没有用布隆过滤器, 因为数量的话, 不算太多).
  * 在 NoSQL 数据库领域使用非常广泛，我们平时用到的 HBase、Cassandra 还有 LevelDB、RocksDB 内部都有布隆过滤器结构，布隆过滤器可以显著降低数据库的 IO 请求数量。当用户来查询某个 row 时，可以先通过内存中的布隆过滤器过滤掉大量不存在的 row 请求，然后再去磁盘进行查询。ES filter 缓存处理。
  * 邮箱系统的垃圾邮件过滤功能，因为用了这个过滤器，所以 时也会遇到某些正常的邮件被放进了垃圾邮件目录中，这个就是误判所致，概率很低。

应用篇——简单限流(滑窗)

* 背景:
  * 当系统的处理能力有限时，如何阻止 计划外的请求继续对系统施压，这是一个需要重视的问题
  * 除了控制流量，限流还有一个应用目的是用于控制用户行为，避免垃圾请求。比如在 UGC 社区，用户的发帖、回复、点赞等行为都要严格受控，一般要严格限定某行为在规定 时间内允许的次数，超过了次数那就是非法行为。对非法行为，业务必须规定适当的惩处策 略。

一个比较常见的策略: 系统要限定某个用户U的某中行为A在指定的时间T里只能允许发生 N 次.

以下几个步骤:

1. 根据用户标识信息, 定位到具体的Key, 也就是定位到具体的 Zset
2. 向该Zset中添加数据: Score=当前毫秒数, value没什么用, 为了省空间但又不重复, 所以也是用当前的毫秒数(这个就是分布式ID的问题了, 不做详细讨论).
3. 删除过期的访问记录, 达到滑窗的效果(这一说, Redis的滑窗是不是也这么搞得呢, 哈哈哈): zremrangeByScore, 利用这个命令删除比当前时间戳小一个时间周期的数据
4. 得到该ZSET中剩余数据的总量, 也就是在当前的时间窗口内的访问次数了.
5. 设置过期时间: 如果用户基本不访问的话, 留着就是浪费了
6. 判断该次数和要求的次数, 大小比较: 大的话, 说明访问次数太多了, 就不让它访问了, 否则就让它访问.

我们假定: 60s 最多访问10次.

**public boolean isActionAllowed(String userId, String actionKey, int period, int maxCount) {**

** /\*\* 定位到具体的Key: 找到对应ZSET. \*\*/**

**  String key = String.format("hist:%s:%s", userId, actionKey);**

** long nowTs = System.currentTimeMillis();**

** Pipeline pipe = jedis.pipelined();**

** pipe.multi();**

** /\*\* 向对应ZSET添加数据: score、value都是 "当前毫秒数". \*\*/**

** pipe.zadd(key, nowTs, "" + nowTs);**

** /\*\* 将当前ZSET中score∈[0, nowTs - period \* 1000]的数据删除掉: 相当于是说, 把比当前时间小60s的数据删除掉, 因为它们已经过期了. \*\*/**

** pipe.zremrangeByScore(key, 0, nowTs - period \* 1000);**

** /\*\* 然后得到该ZSET中数据的总量. \*\*/**

** Response\<Long\> count = pipe.zcard(key);**

** /\*\* 设置当前Key的过期时间: 因为如果这个用户基本不访问的话, 留着就是浪费了. \*\*/**

** pipe.expire(key, period + 1);**

** pipe.exec();**

** pipe.close();**

** /\*\* 判断用户的访问次数是否小于阀值: 小于的话, 就让你访问; 否则的话, 就不让你访问了. \*\*/**

** return count.get() \<= maxCount;**

**}**

* 注意事项
  * zset 集合中只有 score 值非常重要，value 值没有特别的意义，只需要保证它是唯一的就可 以了
  * 因为这几个连续的 Redis 操作都是针对同一个 key 的，使用 pipeline 可以显著提升 Redis 存取效率.
  * 但这种方案也有缺点，因为它要记录时间窗口内所有的行为记录，如果这 个量很大，比如限定 60s 内操作不得超过 100w 次这样的参数(既然做这么限定了, 肯定是说用户的访问量确实相当大)，它是不适合做这样的限流 的，因为会消耗大量的存储空间.

应用篇——漏斗算法

漏斗限流是最常用的限流方法之一。

注意啊: 要把注水, 想象为用户的调用. 漏水, 就是处理请求扩充空间. 它 可以严格限制用户的请求速率.

* 漏斗的关键点: ↓
  * 漏斗的剩余空间: 代表当前行为可以持续进行的数量.
  * 漏嘴的流水速率: 代表系统允许该行为的最大频率.
  * 注意: 漏斗中的剩余空间, 也就是没有水的那一部分, 才是你想要的.

下面看单机版的实现: ↓

 public class FunnelRateLimiter {

 **static class Funnel {**

** /\*\* 容量. \*\*/**

** int capacity;**

** /\*\* 注水速度. 滴水的速度由每次取的值和频率决定. \*\*/**

** float leakingRate;**

** /\*\* 剩余容量. \*\*/**

** int leftQuota;**

** /\*\* 上一次当前时间戳. \*\*/**

** long leakingTs;**

** public Funnel(int capacity, float leakingRate) {**

** this.capacity = capacity;**

** this.leakingRate = leakingRate;**

** this.leftQuota = capacity;**

** this.leakingTs = System.currentTimeMillis();**

** }**

** /\*\* 最主要的就是对剩余容量的设置. \*\*/**

** void makeSpace() {**

** long nowTs = System.currentTimeMillis();**

** long deltaTs = nowTs - leakingTs;**

** /\*\* 我在这一段时间内漏出去了多少水, 空间就应该空出多少来. \*\*/**

** int deltaQuota = (int) (deltaTs \* leakingRate);**

** if (deltaQuota \< 0) { // 间隔时间太长，整数数字过大溢出**

** this.leftQuota = capacity;**

** this.leakingTs = nowTs;**

** return;**

** }**

** if (deltaQuota \< 1) { // 腾出空间太小，最小单位是 1**

** return;**

** }**

** this.leftQuota += deltaQuota;**

** this.leakingTs = nowTs;**

** if (this.leftQuota \> this.capacity) {**

** this.leftQuota = this.capacity;**

** }**

** }**

** /\*\* 灌水: 我想灌这些水****, 行不行. \*\*/**

** boolean addWater(int quota) { quota: 配额, 指标的意思.**

** makeSpace();**

** /\*\* 剩余空间大于要求值, 就允许通过(记得剩余空间要减去漏掉的), 就 \*\*/**

** if (this.leftQuota \>= quota) {**

** this.leftQuota -= quota;**

** return true;**

** }**

** return false;**

** }**

 }

 private Map\<String, Funnel\> funnels = new HashMap\<\>();

 public boolean isActionAllowed(String userId, String actionKey, int capacity, float leakingRate) {

 String key = String.format("%s:%s", userId, actionKey);

 Funnel funnel = funnels.get(key);

 if (funnel == null) {

 funnel = new Funnel(capacity, leakingRate);

 funnels.put(key, funnel);

 }

 return funnel.watering(1); // 需要 1 个 quota

 }

}

* 深入分析: ↓
  * Funnel 对象的 make\_space 方法是漏斗算法的核心，其在每次灌水前都会被调用以触发 漏水，给漏斗腾出空间来。能腾出多少空间取决于过去了多久以及流水的速率。
  * Funnel 对象 占据的空间大小不再和行为的频率成正比，它的空间占用是一个常量。
  * 问题: 分布式的漏斗算法该如何实现？能不能使用 Redis 的基础数据结构来搞定？ 我们观察 Funnel 对象的几个字段，我们发现可以将 Funnel 对象的内容按字段存储到一 个 hash 结构中，灌水的时候将 hash 结构的字段取出来进行逻辑运算后，再将新值回填到 hash 结构中就完成了一次行为频度的检测。 但是有个问题，我们无法保证整个过程的原子性。从 hash 结构中取值，然后在内存里 运算，再回填到 hash 结构，这三个过程无法原子化，意味着需要进行适当的加锁控制。而 一旦加锁，就意味着会有加锁失败，加锁失败就需要选择重试或者放弃。 如果重试的话，就会导致性能下降。如果放弃的话，就会影响用户体验。同时，代码的 复杂度也跟着升高很多。这真是个艰难的选择，我们该如何解决这个问题呢？Redis-Cell 救 星来了

该模块也使用了漏斗算法，并 提供了原子的限流指令。有了这个模块，限流问题就非常简单了。

该模块只有 1 条指令 cl.throttle，它的参数和返回值都略显复杂。

使用案例: cl.throttle laoqian:reply 15 30 60——允许laoqian这个key, reply行为, 60S内执行30次(30/60, 既是漏水速率).

![](resources/A7D75FD4B44832A688167DD576CD7D18)

* 在执行限流指令时，如果被拒绝了，就需要丢弃或重试。cl.throttle 指令考虑的非常周 到，连重试时间都帮你算好了，直接取返回结果数组的第四个值进行 sleep 即可，如果不想 阻塞线程，也可以异步定时任务来重试

====================================================================

限流算法总结: ↓

* 固定窗口: 比如我们规定，对于A接口来说，我们1分钟的访问次数不能超过100个。那么我们可以这么做：在一开 始的时候，我们可以设置一个计数器counter，每当一个请求过来的时候，counter就加1，如果counter的值大于100并且该请求与第一个 请求的间隔时间还在1分钟之内，那么说明请求数过多；如果该请求与第一个请求的间隔时间大于1分钟，且counter的值还在限流范围内，那么就重置 counter
  * 优点: ↓
    * 实现简单
    * 时间窗口固定， 每个窗口开始时计数为零，这样后面的请求不会受到之前的影响，做到了前后请求隔离
  * 缺点: ↓
    * 无法限制窗口间突发流量: 上面优点中的第二点其实也是缺点， 因为两个时间窗口之间没有任何联系， 所以调用者可以在一个时间窗口的结束到下一个时间窗口的开始这个非常短的时间段内发起两倍于阈值的请求.
    * 无法平滑限流, 比如限流10万次/小时， 那调用者可以在1s内调用10万次而不触发限流
* 滑动窗口:
  * 优点:
    * 每次正常请求后时间窗口的过期时间顺延一次，时间窗口是滑动的所以可以抵御窗口间突发流量
  * 缺点: ↓
    * 占用的内存大， 举个例子限流10万次/小时那么就需要维护一个长度为10万的队列
    * 无法平滑限流
    * 
* 漏斗(Redis redis-cell模块, 提供了基于漏斗的限流):
* 令牌桶(Google开源工具包Guava提供了限流工具类RateLimiter, 该类基于令牌桶算法来完成限流).
  * 优点: ↓
    * 可以抵御突发流量， 因为桶内的令牌数不会超过给定的最大值，当然在设置时initToken必须小于等于maxToken
    * 可以做到前后流量隔离， 因为令牌最小值是0
    * 可以做到平滑限流， 因为令牌是匀速放入的
  * 缺点: ↓
    * 相对复杂

* 漏斗和令牌桶的对比:
  * 漏桶算法能够强行限制数据的传输速率
  * 而令牌桶算法能够在限制数据的平均传输速率的同时还允许某种程度的突发传输

应用篇—GEOHash: 查找附近的人

知道就得了，不是很想讲。

应用篇——scan: 大海捞针

* 先说作用，就两个: key的遍历、大key的扫描定位
* 问题：如何从海量的 key 中找出满足特定前缀的 key 列表来？
* 答案：简单暴力的指令 keys: 列出所有满足特定正则字符串规则的 key
* 分析：这个指令使用非常简单，提供一个简单的正则字符串即可，但是有很明显的两个缺点
  * 没有 offset、limit 参数，一次性吐出所有满足条件的 key，万一实例中有几百 w 个 key 满足条件，当你看到满屏的字符串刷的没有尽头时，你就知道难受了
  * keys 算法是遍历算法，复杂度是 O(n)，如果实例中有千万级以上的 key，这个指令 就会导致 Redis 服务卡顿，所有读写 Redis 的其它的指令都会被延后甚至会超时报错，因为 Redis 是单线程程序，顺序执行所有指令，其它指令必须等到当前的 keys 指令执行完了才 可以继续。

* 正解: 大海捞针的指令——scan
* 分析: scan 相比 keys 具备有以下特点:
  * 复杂度虽然也是 O(n)，但是它是通过游标分步进行的，不会阻塞线程
  * 提供 limit 参数，可以控制每次返回结果的最大条数，limit 只是一个 hint，返回的 结果可多可少
  * 同 keys 一样，它也提供模式匹配功能
  * 服务器不需要为游标保存状态，游标的唯一状态就是 scan 返回给客户端的游标整数
  * 返回的结果可能会有重复，需要客户端去重复，这点非常重要
  * 遍历的过程中如果有数据修改，改动后的数据能不能遍历到是不确定的
  * 单次返回的结果是空的并不意味着遍历结束，而要看返回的游标值是否为零

div\>注意: limit 不是限定返回结果的数量，而是限定服务器单次遍历的字典槽位数量(约等于)。 如果将 limit 设置为 10，你会发现返回结果是空的，但是游标值不为零，意味着遍历还没结束

* 原理:
  * 在 Redis 中所有的 key 都存储在一个很大的字典中，这个字典的结构和 Java 中的 HashMap 一样，是一维数组 + 二维链表结构，第一维数组的大小总是 2^n(n\>=0)，扩容一 次数组大小空间加倍，也就是 n++
  * scan 指令返回的游标就是第一维数组的位置索引，我们将这个位置索引称为槽 (slot)。 如果不考虑字典的扩容缩容，直接按数组下标挨个遍历就行了。limit 参数就表示需要遍历的 槽位数，之所以返回的结果可能多可能少，是因为不是所有的槽位上都会挂接链表，有些槽 位可能是空的，还有些槽位上挂接的链表上的元素可能会有多个。每一次遍历都会将 limit 数量的槽位上挂接的所有链表元素进行模式匹配过滤后，一次性返回给客户端
* scan的遍历顺序
  * scan 的遍历顺序非常特别。它不是从第一维数组的第 0 位一直遍历到末尾，而是采用了 高位进位加法 来遍历。之所以使用这样特殊的方式进行遍历，是考虑到字典的扩容和缩容时避免槽位的遍历重复和遗漏
  * 采用高位进位加法的遍历顺序，rehash 后的槽位在遍历顺序上是 相邻的. 这里只是说相邻, 并不是说扩容后的元素就在当前槽位的右侧, 而缩容的就在当前槽位的左侧啊. 这点要注意, 所以有可能会重复遍历.
  * 缩容还是不太一样，它会对图中 010 这个槽位上的元素进行重复遍历，因为 缩融后 10 槽位的元素是 010 和 110 上挂接的元素的融合
* 渐进式 rehash
  * Java 的 HashMap 在扩容时会一次性将旧数组下挂接的元素全部转移到新数组下面。
  * 如果 HashMap 中元素特别多，线程就会出现卡顿现象。Redis 为了解决这个问题，它采用渐进式 rehash。 它会同时保留旧数组和新数组，然后在定时任务中以及后续对 hash 的指令操作中渐渐 地将旧数组中挂接的元素迁移到新数组上。这意味着要操作处于 rehash 中的字典，需要同 时访问新旧两个数组结构。如果在旧数组下面找不到元素，还需要去新数组下面去寻找。 scan 也需要考虑这个问题，对与 rehash 中的字典，它需要同时扫描新旧槽位，然后将 结果融合后返回给客户端。

* 大key扫描:

有时候会因为业务人员使用不当，在 Redis 实例中会形成很大的对象，比如一个很大的 hash，一个很大的 zset 这都是经常出现的。这样的对象对 Redis 的集群数据迁移带来了很 大的问题，因为在集群环境下，如果某个 key 太大，会数据导致迁移卡顿。另外在内存分配 上，如果一个 key 太大，那么当它需要扩容时，会一次性申请更大的一块内存，这也会导致 卡顿。如果这个大 key 被删除，内存会一次性回收，卡顿现象会再一次产生。 在平时的业务开发中，要尽量避免大 key 的产生。 如果你观察到 Redis 的内存大起大落，这极有可能是因为大 key 导致的，这时候你就 需要定位出具体是那个 key，进一步定位出具体的业务来源，然后再改进相关业务代码设 计。 scan 指令，对于扫描出来的每一个 key，使用 type 指令获得 key 的类型，然后使用相应数据结构的 size 或者 len 方法来得到 它的大小，对于每一种类型，保留大小的前 N 名作为扫描结果展示出来。 上面这样的过程需要编写脚本，比较繁琐，不过 Redis 官方已经在 redis-cli 指令中提供 了这样的扫描功能，我们可以直接拿来即用。 

* redis-cli -h 127.0.0.1 -p 7001 –-bigkeys
  * 如果你担心这个指令会大幅抬升 Redis 的 ops 导致线上报警，还可以增加一个休眠参 数。
* redis-cli -h 127.0.0.1 -p 7001 –-bigkeys -i 0.1
  * 上面这个指令每隔 100 条 scan 指令就会休眠 0.1s，ops 就不会剧烈抬升，但是扫描的 时间会变长

第二部分: 原理篇——共4节.

二: 原理篇——线程I/O模型(这里可以去看Redis设计与实现)

最小堆的事情要记住啊

Redis 是个单线程程序。 因为它所有的数据都在内存中，所有的运算都是内存级别的运算。正因为 Redis 是单线 程，所以要小心使用 Redis 指令，对于那些时间复杂度为 O(n) 级别的指令，一定要谨慎使 用，一不小心就可能会导致 Redis 卡顿。 Redis 单线程如何处理那么多的并发客户端连接？ 这个问题，有很多中高级程序员都无法回答，因为他们没听过多路复用这个词汇，不知 道 select 系列的事件轮询 API，没用过非阻塞 IO。

非阻塞 IO 在套接字对象上提供了一个选项 Non\_Blocking，当这个选项打开时，读写方 法不会阻塞，而是能读多少读多少，能写多少写多少。能读多少取决于内核为套接字分配的 读缓冲区内部的数据字节数，能写多少取决于内核为套接字分配的写缓冲区的空闲空间字节数。还提供了一个 timeout 参数，如果没有任何事件到来，那么就最多 等待 timeout 时间，线程处于阻塞状态。一旦期间有任何事件到来，就可以立即返回。时间过 了之后还是没有任何事件到来，也会立即返回。拿到事件后，线程就可以继续挨个处理相应 的事件。处理完了继续过来轮询。于是线程就进入了一个死循环，我们把这个死循环称为事件循环，一个循环为一个周期。

服务器处理要响应 IO 事件外，还要处理其它事情。比如定时任务就是非常重要的一件 事。如果线程阻塞在 select 系统调用上，定时任务将无法得到准时调度。那 Redis 是如何解 决这个问题的呢？ Redis 的定时任务会记录在一个称为最小堆的数据结构中。这个堆中，最快要执行的任 务排在堆的最上方。在每个循环周期，Redis 都会将最小堆里面已经到点的任务立即进行处 理。处理完毕后，将最快要执行的任务还需要的时间记录下来，这个时间就是 select 系统调 用的 timeout 参数。因为 Redis 知道未来 timeout 时间内，没有其它定时任务需要处理，所以 可以安心睡眠 timeout 的时间

二: 原理篇——交头接耳——通信协议

* Redis 的作者认为数据库系统的瓶颈一般不在于网络流量，而是数据库自身内部逻辑处理上。所以即使 Redis 使用了浪费流量的文本协议，依然可以取得极高的访问性能。
  * Redis 将所有数据都放在内存，用一个单线程对外提供服务，单个节点在跑满一个 CPU 核心的情 况下可以达到了 10w/s 的超高 QPS。
* Redis使用RESP协议(Redis Serialication Protocol), 它是一种直观的文本协议，优势在于实现异常简单，解析性能极好.
* Redis 协议将传输的结构数据分为 5 种最小单元类型，单元结束时统一加上回车换行符号 \\r\\n
  * 整数值
  * 单行字符串
  * 多行字符串
  * 数组
  * 错误消息
* 客户端\<——\>服务端通信
  * 客户端向服务器发送的指令只有一种格式，多行字符串数组
  * 服务器向客户端回复的响应要支持多种数据结构，所以消息响应在结构上要复杂不少。 不过再复杂的响应消息也是以上 5 中基本类型的组合
* Redis 协议里有大量冗余的回车换行符，但是这不影响它成为互联网技术领域非常受欢 迎的一个文本协议。有很多开源项目使用 RESP 作为它的通讯协议。
  * 在技术领域性能并不总是一切，还有简单性、易理解性和易实现性，这些都需要进行适当权衡.

二: 原理篇——持久化

* 简介: Redis 的持久化机制有两种
  * 快照: 内存的一个快照. 内存数据的二进制序列化形式，在存储上非常紧凑
  * AOF 日志: 记录对内存数据修改的指令
    * AOF 日志在长期的运行过程中会 变的无比庞大，数据库重启时需要加载 AOF 日志进行指令重放，这个时间就会无比漫长。
    * 所以需要定期进行 AOF 重写，给 AOF 日志进行瘦身
* RDB介绍:
  * 触发条件
    * 手动触发: save、bgsave(一般用这个)
    * 自动触发: 下面的参数不用看, 知道有这么回事就可以了啊哈. O(∩\_∩)O~
      * save 900 1：表示900 秒内如果至少有 1 个 key 的值变化，则保存
      * save 300 10：表示300 秒内如果至少有 10 个 key 的值变化，则保存
      * save 60 10000：表示60 秒内如果至少有 10000 个 key 的值变化，则保存
  * 原理:
    * Redis 是单线程程序, 需要对客户端进行读写操作, 在服务线上请求的同时，Redis 还需要进行内存快照，内存快照要求 Redis 必须进行文件 IO 操作. 文件 IO 操作会严重拖 垮服务器请求的性能。
    * 问题
      * 还有个重要的问题是为了不阻塞线上的业务，就需要边持久化边响应 客户端请求。
      * 持久化的同时，内存数据结构还在改变
        * 比如 一个大型的 hash 字典正在持久化，结果一个请求过来把它给删掉了，还没持久化完呢，这尼玛要怎么搞？
    * Redis 使用操作系统多进程的 COW(Copy On Write) 机制来实现快照持久化
      * Redis 在持久化时会 fork 出一个子进程，快照持久化完全交给子进程来处理，父进程继续处理客户端请求。
      * 子进程刚刚产生时，它和父进程共享内存里面的代 码段和数据段. 所以在刚创建出来时, 内存的 增长几乎没有明显变化。
      * 子进程做数据持久化，它不会修改现有的内存数据结构，它只是对数据结构进行遍历读取，然后序列化写到磁盘中。
      * 但是父进程不一样，它必须持续服务客户端请求，然后对内存 数据结构进行不间断的修改。
      * 这个时候就会使用操作系统的 COW 机制来进行数据段页面的分离。 当父进程对其中一个页面的数据进行修改时，会将被共享的页面复 制一份分离出来，然后对这个复制的页面进行修改。这时子进程相应的页面是没有变化的， 还是进程产生时那一瞬间的数据。 随着父进程修改操作的持续进行，越来越多的共享页面被分离出来，内存就会持续增 长。但是也不会超过原有数据内存的 2 倍大小(因为客户端不可能说对所有的key都进行操作啊), Redis 实例里冷数据占的比例往 往是比较高的，所以很少会出现所有的页面都会被分离，被分离的往往只有其中一部分页面。 子进程因为数据没有变化，它能看到的内存里的数据在进程产生的一瞬间就凝固了，再 也不会改变，这也是为什么 Redis 的持久化叫「快照」的原因。接下来子进程就可以非常安 心的遍历数据了进行序列化写磁盘了。

AOP介绍

* 简介
  * AOF 日志存储的是 Redis 指令序列，对内存进行修改的 指令记录. 突发宕机，已经存储到 AOF 日志的指令进行重放一下就可以恢复到宕机前的状态。
    * 需要注意的是, 它是先记录到AOF日志中, 再执行命令.
  * Redis 在长期运行的过程中，AOF 的日志会越变越长。如果实例宕机重启，重放整个 AOF 日志会非常耗时，导致长时间 Redis 无法对外提供服务。所以需要对 AOF 日志瘦身。
  * AOF瘦身(其实也就是AOF 重写): Redis 提供了 bgrewriteaof 指令用于对 AOF 日志进行瘦身。
    * 原理
      * 开辟一个子进 程对内存进行遍历转换成一系列 Redis 的操作指令，序列化到一个新的 AOF 日志文件中。
      * 序列化完毕后再将操作期间发生的增量 AOF 日志追加到这个新的 AOF 日志文件中，追加 完毕后就立即替代旧的 AOF 日志文件了，瘦身工作就完成了。
  * 原理:
    * 程序对 AOF 日志文件进行写操作时，实际上是将 内容写到了内核为文件描述符分配的一个内存缓存中，然后内核会异步将脏数据刷回到磁盘 的。 这就意味着如果机器突然宕机，AOF 日志内容可能还没有来得及完全刷到磁盘中，这个 时候就会出现日志丢失
    * Linux 的 glibc 提供了 fsync(int fd)函数可以将指定文件的内容强制从内核缓存刷到磁 盘。只要 Redis 进程实时调用 fsync 函数就可以保证 aof 日志不丢失。但是 fsync 是一个 磁盘 IO 操作，它很慢！如果 Redis 执行一条指令就要 fsync 一次，那么 Redis 高性能的 地位就不保了
    * 所以在生产环境的服务器中，Redis 通常是每隔 1s 左右执行一次 fsync 操作，周期 1s 是可以配置的。这是在数据安全性和性能之间做了一个折中，在保持高性能的同时，尽可能 使得数据少丢失
      * Redis 同样也提供了另外两种策略，一个是永不 fsync——让操作系统来决定合适同步磁 盘，很不安全，另一个是来一个指令就 fsync 一次——非常慢。但是在生产环境基本不会使 用，了解一下即可

* 两者的一个比对:
  * RDB: 快照是通过开启子进程的方式进行的，它是一个比较耗资源的操作
    * 遍历整个内存，大块写磁盘会加重系统负载
  * AOF
    * AOF 的 fsync 是一个耗时的 IO 操作，它会降低 Redis 性能，同时也会增加系 统 IO 负担
* 结论:
  * 所以通常 Redis 的主节点是不会进行持久化操作，持久化操作主要在从节点进行。从节 点是备份节点，没有来自客户端请求的压力，它的操作系统资源往往比较充沛
    * 但是如果出现网络分区，从节点长期连不上主节点，就会出现数据不一致的问题，特别 是在网络分区出现的情况下又不小心主节点宕机了，那么数据就会丢失
      * 还应该再增加一个从节点以降低网 络分区的概率，只要有一个从节点数据同步正常，数据也就不会轻易丢失
* Redis 4.0 混合持久化
  * 重启 Redis 时，使用 rdb 来恢复内存状态，会丢失大量数据
  * 使用 AOF 日志重放, 性能相对 rdb 来说要慢很多，这样在 Redis 实 例很大的情况下，启动需要花费很长的时间
  * Redis 4.0 为了解决这个问题，带来了一个新的持久化选项——混合持久化
    * 将 rdb 文 件的内容和增量的 AOF 日志文件存在一起。这里的 AOF 日志不再是全量的日志，而是自 持久化开始到持久化结束的这段时间发生的增量 AOF 日志，通常这部分 AOF 日志很小
    * 于是在 Redis 重启的时候，可以先加载 rdb 的内容，然后再重放增量 AOF 日志就可 以完全替代之前的 AOF 全量文件重放，重启效率因此大幅得到提升

二: 原理篇——管道

* Redis 管道 (Pipeline) 本身并不是 Redis 服务器直接提供的技术，这个技术本质上是由客户端提供的， 跟服务器没有什么直接的关系
* 通过管道，将请求进行合并。两个连续的写操作和两个连续的读操作总共只会花费一次网络来回，就好比连续的 write 操作合并了，连续的 read 操作也合并了一样
  * 这便是管道操作的本质，服务器根本没有任何区别对待，还是收到一条消息，执行一条 消息，回复一条消息的正常的流程。客户端通过对管道中的指令列表改变读写顺序就可以大 幅节省 IO 时间。管道中指令越多，效果越好
* 管道的真实本质:
  * 先看一下, 一个请求的真正流程(要经过网络协 议栈，这个就得深入内核了): ↓
    1. 客户端进程调用 write 将消息写到操作系统内核为套接字分配的发送缓冲 send buffer。
    2. 客户端操作系统内核将发送缓冲的内容发送到网卡，网卡硬件将数据通过「网际路 由」送到服务器的网卡
    3. 服务器操作系统内核将网卡的数据放到内核为套接字分配的接收缓冲 recv buffer。
    4. 服务器进程调用 read 从接收缓冲中取出消息进行处理。
    5. 服务器进程调用 write 将响应消息写到内核为套接字分配的发送缓冲 send buffer。
    6. 服务器操作系统内核将发送缓冲的内容发送到网卡，网卡硬件将数据通过「网际路 由」送到客户端的网卡
    7. 客户端操作系统内核将网卡的数据放到内核为套接字分配的接收缓冲 recv buffer。
    8. 客户端进程调用 read 从接收缓冲中取出消息返回给上层业务逻辑进行处理
    9. 结束。
  * 我们开始以为 write 操作是要等到对方收到消息才会返回，但实际上不是这样的。write 操作只负责将数据写到本地操作系统内核的发送缓冲然后就返回了。剩下的事交给操作系统 内核异步将数据送到目标机器。但是如果发送缓冲满了，那么就需要等待缓冲空出空闲空间 来，这个就是写操作 IO 操作的真正耗时
  * 我们开始以为 read 操作是从目标机器拉取数据，但实际上不是这样的。read 操作只负 责将数据从本地操作系统内核的接收缓冲中取出来就了事了。但是如果缓冲是空的，那么就 需要等待数据到来，这个就是读操作 IO 操作的真正耗时
  * 所以对于 value = redis.get(key)这样一个简单的请求来说，write 操作几乎没有耗时，直接 写到发送缓冲就返回，而 read 就会比较耗时了，因为它要等待消息经过网络路由到目标机器 处理后的响应消息,再回送到当前的内核读缓冲才可以返回。这才是一个网络来回的真正开 销。
  * 而对于管道来说，连续的 write 操作根本就没有耗时，之后第一个 read 操作会真正等待一个 网络的来回开销，然后所有的响应消息就都已经回送到内核的读缓冲了，后续的 read 操作 直接就可以从缓冲拿到结果，瞬间就返回了.
* 总结: 这就是管道的本质了，它并不是服务器的什么特性，而是客户端通过改变了读写的顺序 带来的性能的巨大提升。

二: 原理篇——小对象压缩

看过了, 回来再做笔记. 有的地方不是很明白. 哈哈O(∩\_∩)O~

* 如果 Redis 内部管理的集合数据结构很小，它会使用紧凑存储形式压缩存储。
  * ziplist: hash、zset(Value不能重复, 为Value关联一个double类型的score)
    * Redis 的 ziplist 是一个紧凑的字节数组结构，如下图所示，每个元素之间都是紧挨着 的
    * 如果它存储的是 hash 结构，那么 key 和 value 会作为两个 entry 相邻存在一起
    * 如果它存储的是 zset，那么 value 和 score 会作为两个 entry 相邻存在一起
  * inset: set数据很少时的一个实现. uint16 ------\> uint32 ------\> uint64\. 随时升级为 hashtable
    * Redis 的 intset 是一个紧凑的整数数组结构，它用于存放元素都是整数的并且元素个数 较少的 set 集合
    * 如果整数可以用 uint16 表示，那么 intset 的元素就是 16 位的数组
    * 如果新加入的整 数超过了 uint16 的表示范围，那么就使用 uint32 表示
    * 如果新加入的元素超过了 uint32 的表示范围，那么就使用 uint64 表示
    * Redis 支持 set 集合动态从 uint16 升级到 uint32， 再升级到 uint64
    * 如果 set 里存储的是字符串，那么 sadd 立即升级为 hashtable 结构
    * 
* 升级
  * 当集合对象的元素不断增加，或者某个 value 值过大，这种小对象存储也会 被升级为标准结构
  * 下面是升级的规则
    * hash
      * 元素个数超过 512 就必须用标准结构存储
      * 任意元素的 key/value 的长度超过 64
    * list
      * 元素个数超过 512
      * 任意元素的长度超过 64
    * zset
      * 元素个数超过 128
      * 任意元素的长度超过 64
    * set
      * 整数元素个数超过 512
* 内存回收机制
  * Redis 并不总是可以将空闲内存立即归还给操作系统。 如果当前 Redis 内存有 10G，当你删除了 1GB 的 key 后，再去观察内存，你会发现 内存变化不会太大。原因是操作系统回收内存是以页为单位，如果这个页上只要有一个 key 还在使用，那么它就不能被回收。Redis 虽然删除了 1GB 的 key，但是这些 key 分散到了 很多页面中，每个页面都还有其它 key 存在，这就导致了内存不会立即被回收。 不过，如果你执行 flushdb，然后再观察内存会发现内存确实被回收了。原因是所有的 key 都干掉了，大部分之前使用的页面都完全干净了，会立即被操作系统回收。 Redis 虽然无法保证立即回收已经删除的 key 的内存，但是它会重用那些尚未回收的空 闲内存。这就好比电影院里虽然人走了，但是座位还在，下一波观众来了，直接坐就行。而 操作系统回收内存就好比把座位都给搬走了。这个比喻是不是很 6？
* 内存分配
  * 内存分配是一个非常复杂的课题，需要适当的算法划分内存页，需要考虑内存碎片，需 要平衡性能和效率。 Redis 为了保持自身结构的简单性，在内存分配这里直接做了甩手掌柜，将内存分配的 细节丢给了第三方内存分配库去实现。目前 Redis 可以使用 jemalloc(facebook) 库来管理内 存，也可以切换到 tcmalloc(google)。因为 jemalloc 相比 tcmalloc 的性能要稍好一些，所以 Redis 默认使用了 jemalloc

三: 集群篇——主从同步

* 先说在前面的话: 记住了啊, Redis是最终一致性. 所以它满足的是 AP. 它是异步复制的, 记住这句话: Redis是异步复制的.
* CAP 理论
  * C - Consistent ，一致性
  * A - Availability ，可用性
  * P - Partition tolerance ，分区容忍性
* 分布式系统的节点往往都是分布在不同的机器上进行网络隔离开的，这意味着必然会有 网络断开的风险，这个网络断开的场景的专业词汇叫着「网络分区」。 在网络分区发生时，两个分布式节点之间无法进行通信，我们对一个节点进行的修改操 作将无法同步到另外一个节点，所以数据的「一致性」将无法满足，因为两个分布式节点的 数据不再保持一致。除非我们牺牲「可用性」，也就是暂停分布式节点服务，在网络分区发 生时，不再提供修改数据的功能，直到网络状况完全恢复正常再继续对外提供服务。
* 一句话概括 CAP 原理就是——网络分区发生时，一致性和可用性两难全。(注意前提: 是网络分区发生的时候).
* 最终一致性: Redis 的主从数据是异步同步的，所以分布式的 Redis 系统并不满足「一致性」要求。 当客户端在 Redis 的主节点修改了数据后，立即返回，即使在主从网络断开的情况下，主节 点依旧可以正常对外提供修改服务，所以 Redis 满足「可用性」
* Redis 保证「最终一致性」，从节点会努力追赶主节点，最终从节点的状态会和主节点 的状态将保持一致。如果网络断开了，主从节点的数据将会出现大量不一致，一旦网络恢 复，从节点会采用多种策略努力追赶上落后的数据，继续尽力保持和主节点一致
* Redis的同步, 支持 主从同步 和 从从同步. 为了叙述方便， 我们统一称为 "主从同步".
* 增量同步
  * Redis 同步的是指令流，主节点会将那些对自己的状态产生修改性影响的指令记录在本 地的内存 buffer 中，然后异步将 buffer 中的指令同步到从节点，从节点一边执行同步的指 令流来达到和主节点一样的状态，一遍向主节点反馈自己同步到哪里了 (偏移量)。 因为内存的 buffer 是有限的，所以 Redis 主库不能将所有的指令都记录在内存 buffer 中。Redis 的复制内存 buffer 是一个定长的环形数组，如果数组内容满了，就会从头开始覆 盖前面的内容。 如果因为网络状况不好，从节点在短时间内无法和主节点进行同步，那么当网络状况恢 复时，Redis 的主节点中那些没有同步的指令在 buffer 中有可能已经被后续的指令覆盖掉 了，从节点将无法直接通过指令流来进行同步，这个时候就需要用到更加复杂的同步机制 — — 快照同步。
* 快照同步
  * 快照同步是一个非常耗费资源的操作，它首先需要在主库上进行一次 bgsave 将当前内存的数据全部快照到磁盘文件(注意: 这里涉及到了硬盘了)中，然后再将快照文件的内容全部传送到从节点。从节点将快照文件接受完毕后，立即执行一次全量加载，加载之前先要将当前内存的数据清空。加载完 毕后通知主节点继续进行增量同步. 在整个快照同步进行的过程中，主节点的复制 buffer 还在不停的往前移动，如果快照同 步的时间过长或者复制 buffer 太小，都会导致同步期间的增量指令在复制 buffer 中被覆盖，这样就会导致快照同步完成后无法进行增量复制，然后会再次发起快照同步，如此极有 可能会陷入快照同步的死循环。 所以务必配置一个合适的复制 buffer 大小参数，避免快照复制的死循环。
* 增加从节点: 当从节点刚刚加入到集群时，它必须先要进行一次快照同步，同步完成后再继续进行增量同步.
* 无盘复制:
  * 主节点在进行快照同步时，会进行很重的文件 IO 操作, 因为要将内存的数据写到硬盘. 如果系统正在进行 AOF 的 fsync 操作时如果发生快照，fsync 将会被推迟执行, 这就会严重影响主节点的服务效率. 所以从 Redis 2.8.18 版开始支持无盘复制。
  * 所谓无盘复制是指主服务器直接通过套接字 将快照内容发送到从节点，
  * 生成快照是一个遍历的过程，主节点会一边遍历内存，一遍将序 列化的内容发送到从节点，从节点还是跟之前一样，先将接收到的内容存储到磁盘文件中， 再进行一次性加载。

(Redis 的复制是异步进行的，wait 指令可以让异步复制变身同步复制).

主从复制是 Redis 分布式的基础，Redis 的高可用离开了主从复制将无从进行.

三: 集群篇——Sentinel哨兵模式(可以去看Redis设计与实现那本书)

高可用方案来抵抗节点故障—— Redis Sentinel(哨兵).

* 从上图中,&[](resources/)is节点, 不对外提供Key的读写服务.
* 哨兵节点, 不是只有一台的.

对哨兵模式的简介:

* 它负责持续监控主从节点的健康，当主节点挂掉时，自动选择一个最优的从节点切换为主节点(这里是有很多指标的, 比如 较大的replication offset: 每个slave在与master同步后offset自动增加)。客户端来连接集群时，会首先连接 sentinel，通过 sentinel 来查询主节点的地址， 然后再去连接主节点进行数据交互。当主节点发生故障时，客户端会重新向 sentinel 要地 址，sentinel 会将最新的主节点地址告诉客户端。如此应用程序将无需重启即可自动完成节点切换
* 主节点挂掉了，发生的一些事情
  * 原先的主从复制也断开了，
  * 客户端和损坏的主节 点也断开了。
  * 从节点被提升为新的主节点，其它从节点开始和新的主节点建立复制关系。
  * 客户端通过新的主节点继续进行交互。
  * Sentinel 会持续监控已经挂掉了主节点，待它恢复后，会变成从节点，从新的主节点那里建立复制关系
* 消息丢失: Redis 主从采用异步复制，意味着当主节点挂掉时，从节点可能没有收到全部的同步消息，这部分未同步的消息就丢失了。如果主从延迟特别大，那么丢失的数据就可能会特别 多。Sentinel 无法保证消息完全不丢失，但是也尽可能保证消息少丢失。它有两个选项可以 限制主从延迟过大.
  * 下面两个参数可以进行配置:
    * min-slaves-to-write 1
    * min-slaves-max-lag 10
  * 第一个参数表示主节点必须至少有一个从节点在进行正常复制，否则就停止对外写服 务，丧失可用性。 何为正常复制，何为异常复制？这个就是由第二个参数控制的，它的单位是秒，表示如 果 10s 没有收到从节点的反馈，就意味着从节点同步不正常，要么网络断开了，要么一直没有给反馈

三: 集群篇——众志成城Cluster(也可以去看那本书)

* 背景:
  * 在大数据高并发场景下，单个 Redis 实例往往会显得捉襟见肘。
  * 首先体现在内存上，单 个 Redis 的内存不宜过大，内存太大会导致 rdb 文件过大，进一步导致主从同步时全量同 步时间过长，在实例重启恢复时也会消耗很长的数据加载时间，特别是在云环境下，单个实 例内存往往都是受限的。
  * 其次体现在 CPU 的利用率上，单个 Redis 实例只能利用单个核心(因为单线程)，这单个核心要完成海量数据的存取和管理工作压力会非常大。 正是在这样的大数据高并发的需求之下，Redis 集群方案应运而生。它可以将众多小内 存的 Redis 实例综合起来，将分布在多台机器上的众多 CPU 核心的计算能力聚集到一起， 完成海量数据存储和高并发读写操作。
* 中国人的集群: Codis 是 Redis 集群方案之一，令我们感到骄傲的是，它是中国人开发并开源的，来自 前豌豆荚中间件团队。绝大多数国内的开源项目都不怎么靠谱，但是 Codis 非常靠谱。有了 Codis 技术积累之后，项目「突头人」刘奇又开发出来中国人自己的开源分布式数据库 —— TiDB，可以说 6 到飞起.

但是, 我这里说的是Cluster, 而不是Codis, 抱歉了哈~ O(∩\_∩)O~

* Redis Cluster 简介
  * 去中心化: 每个节点负责整个集群的一部分数据，负责的数据多少可能不一样.
  * 槽位: Redis Cluster 将所有数据划分为 16384(记住这个值啊) 个槽位, 每个节点负责其中一部分槽位(注意啊: 不一定是1对1 的关系啊O(∩\_∩)O~). 槽位的信息存储于每个节点中. 当 Redis Cluster 的客户端来连接集群时，它也会得到一份集群的槽位配置信息。这样当 客户端要查找某个 key 时，可以直接定位到目标节点
  * 客户端为了可以直接定位某个具体的 key 所在的节点，会缓存槽位相关信息. 但是槽位的信息存在客户端和服务器之间可能会不一致，还需要纠正机制来实现槽位信息的校验调整
  * 槽位定位: Cluster 默认会对key值使用crc32算法进行hash得到一个整数值，然后用这个整数值对16384进行取模来得到具体槽位. Cluster 还允许用户强制某个 key 挂在特定槽位上，通过在 key 字符串里面嵌入 tag 标 记，这就可以强制 key 所挂在的槽位等于 tag 所在的槽位.
  * 跳转: 当客户端向一个错误的节点发出了指令，该节点会发现指令的 key 所在的槽位并不归自 己管理，这时它会向客户端发送一个特殊的跳转指令携带目标操作的节点地址，告诉客户端 去连这个节点去获取数据。
  * 数据的迁移: Redis 迁移的单位是槽，Redis 一个槽一个槽进行迁移，当一个槽正在迁移时，这个槽就处于中间过渡状态。这个槽在原节点的状态为 migrating，在目标节点的状态为 importing，表示数据正在从源流向目标。简单总结就是, 从源节点获取内容 =\> 存到目标节点 =\> 从源节点删除内容。 迁移过程是同步的, 原节点的主线程会处于阻塞状态, 直到key被成功删除. 在迁移过程中，如果每个 key 的内容都很小，迁移执行会很快，它就并不会影响 客户端的正常访问。如果 key 的内容很大，会导致原节点和目标节点卡顿，影响集群的稳定型。所以在集群环境下业务逻辑要尽可能避免大 key 的产 生
  * 数据迁移中的数据访问: 先新旧两个节点对应的槽位都存在部分 key 数据。客户端先尝试访问旧节点，如果对 应的数据还在旧节点里面，那么旧节点正常处理。如果对应的数据不在旧节点里面，那么有 两种可能，要么该数据在新节点里，要么根本就不存在。旧节点不知道是哪种情况，所以它 会向客户端返回一个-ASK targetNodeAddr 的重定向指令。客户端收到这个重定向指令后，先 去目标节点执行一个不带任何参数的 asking 指令，然后在目标节点再重新执行原先的操作指 令
    * 为什么需要执行一个不带参数的 asking 指令呢
      * 因为在迁移没有完成之前，按理说这个槽位还是不归新节点管理的，如果这个时候向目 标节点发送该槽位的指令，节点是不认的，它会向客户端返回一个-MOVED 重定向指令告诉它去源节点去执行。如此就会形成 重定向循环。asking 指令的目标就是打开目标节点的选项，告诉它下一条指令不能不理，而要当成自己的槽位来处理.
  * 容错: Redis Cluster 可以为每个主节点设置若干个从节点，当主节点故障时，集群会自动将其中某个从节点提升为主节点。如果某个主节点没有从节点，那么当它发生故障时，集群将完 全处于不可用状态。不过Redis也提供了一个参数 cluster-require-full-coverage 可以允许部分 节点故障，其它节点还可以继续提供对外访问.
  * 网络抖动: 为解决这个问题，Redis Cluster 提供了一种选项 cluster-node-timeout，表示当某个节点持 续 timeout 的时间失联时，才可以认定该节点出现故障，需要进行主从切换。如果没有这个 选项，网络抖动会导致主从频繁切换 (数据的重新复制)。
  * 节点下线(Fail)和可能下线(PFail)
    * Redis Cluster 是去中心化的，一个节点认为某个节点失联了并不代表所有的节点都认为它失联了。所以集群还得经过一次协商的过程，只有当大多数节点都认定了某个节点失联了，集群才认为该节点需要进行主从切换来容错
    * Redis 集群节点采用 Gossip 协议来广播自己的状态以及自己对整个集群认知的改变。比如一个节点发现某个节点失联了 (PFail)，它会将这条信息向整个集群广播，其它节点也就可 以收到这点失联信息。如果一个节点收到了某个节点失联的数量 (PFail Count) 已经达到了集群的大多数，就可以标记该节点为确定下线状态 (Fail)，然后向整个集群广播，强迫其它节点也接收该节点已经下线的事实，并立即对该失联节点进行主从切换
  * 槽位迁移感知: 如果 Cluster 中某个槽位正在迁移或者已经迁移完了，client 如何能感知到槽位的变化 呢？客户端保存了槽位和节点的映射关系表，它需要即时得到更新，才可以正常地将某条指 令发到正确的节点中。 我们前面提到 Cluster 有两个特殊的 error 指令，一个是 moved，一个是 asking。
    * moved: 用来纠正槽位的。如果我们将指令发送到了错误的节点，该节点发现 对应的指令槽位不归自己管理，就会将目标节点的地址随同 moved 指令回复给客户端通知 客户端去目标节点去访问。这个时候客户端就会刷新自己的槽位关系表，然后重试指令，后 续所有打在该槽位的指令都会转到目标节点
    * asking: 该指令和 moved 不一样，它是用来临时纠正槽位的。如果当前槽位正处于 迁移中，指令会先被发送到槽位所在的旧节点，如果旧节点存在数据，那就直接返回结果 了，如果不存在，那么它可能真的不存在也可能在迁移目标节点上。所以旧节点会通知客户 端去新节点尝试一下拿数据，看看新节点有没有。这时候就会给客户端返回一个 asking error 携带上目标节点的地址。客户端收到这个 asking error 后，就会去目标节点去尝试。客户端 不会刷新槽位映射关系表，因为它只是临时纠正该指令的槽位信息，不影响后续指令.

四: 拓展篇——无所不知——Info指令

这个指令不会介绍太多的.

在使用 Redis 时，时常会遇到很多问题需要诊断，在诊断之前需要了解 Redis 的运行状 态，通过强大的 Info 指令，你可以清晰地知道 Redis 内部一系列运行参数。

* Redis 每秒执行多少次指令
* Redis 连接了多少客户端
* Redis 内存占用多大
* 复制积压缓冲区多大

四: 拓展篇——朝生暮死——过期策略

* 注意啊
  * 这里的 过期策略 和 lru 没什么关系啊, 这里是Key过期了要删掉;
  * lru是缓存淘汰, 内存不足了, 淘汰掉一部分数据.
* Redis 所有的数据结构都可以设置过期时间，时间一到，就会自动删除。你可以想象 Redis 内部有一个死神，时刻盯着所有设置了过期时间的 key，寿命一到就会立即收割。
* 删除策略
  * redis 会将每个设置了过期时间的 key 放入到一个独立的字典中，以后会定时遍历这个 字典来删除到期的 key。
  * 除了定时遍历之外，它还会使用惰性策略来删除过期的 key，所谓 惰性策略就是在客户端访问这个 key 的时候，redis 对 key 的过期时间进行检查，如果过期 了就立即删除。
  * 定时删除是集中批量处理，惰性删除是零散处理
* 定时扫描策略
  * Redis 默认会每秒进行十次过期扫描，过期扫描不会遍历过期字典中所有的 key，而是 采用了一种简单的贪心策略。
    1. 从过期字典中随机 20 个 key；
    2. 删除这 20 个 key 中已经过期的 key；
    3. 如果过期的 key 比率超过 1/4，那就重复步骤 1；
  * 为了保证过期扫描不会出现循环过度，导致线程卡死现象，算法还增加了扫描时间的上限，默认不会超过 25ms
  * 一个大型的 Redis 实例中所有的 key 在同一时间过期了, Redis 会持续扫描过期字典 (循环多次)，直到过期字典中过期的 key 变得稀 疏，才会停止 (循环次数明显下降)。这就会导致线上读写请求出现明显的卡顿现象。导致这 种卡顿的另外一种原因是内存管理器需要频繁回收内存页，这也会产生一定的 CPU 消耗
  * 也许你会争辩说“扫描不是有 25ms 的时间上限了么，怎么会导致卡顿呢”？这里打个 比方，假如有 101 个客户端同时将请求发过来了，然后前 100 个请求的执行时间都是 25ms，那么第 101 个指令需要等待多久才能执行？2500ms，这个就是客户端的卡顿时间， 是由服务器不间断的小卡顿积少成多导致的。
* 从节点的过期策略: 从节点没有过期策略, 它是通过主节点的同步指令来删除的.
  * 从节点不会进行过期扫描，从节点对过期的处理是被动的。主节点在 key 到期时，会在 AOF 文件里增加一条 del 指令，同步到所有的从节点，从节点通过执行这条 del 指令来删除过期的 key。 因为指令同步是异步进行的，所以主节点过期的 key 的 del 指令没有及时同步到从节点的 话，会出现主从数据的不一致，主节点没有的数据在从节点里还存在，会造成集群环境分布式锁的算法漏洞.

四: 拓展篇——优胜劣汰 —— LRU

* 注意啊, 这个和上一篇不一样, 上一篇指的是Key失效了, 需要进行删除. 而这里指的是内存满了.
* 当 Redis 内存超出物理内存限制时，内存的数据会开始和磁盘产生频繁的交换 (swap)。 交换会让 Redis 的性能急剧下降，对于访问量比较频繁的 Redis 来说，这样龟速的存取效率 基本上等于不可用。
  * 在生产环境中我们是不允许 Redis 出现交换行为的，为了限制最大使用内存，Redis 提 供了配置参数 maxmemory 来限制内存超出期望大小。 当实际内存超出 maxmemory 时，Redis 提供了几种可选策略 (maxmemory-policy) 来让 用户自己决定该如何腾出新的空间以继续提供读写服务
    * noeviction 不会继续服务写请求 (DEL 请求可以继续服务)，读请求可以继续进行。这样 可以保证不会丢失数据，但是会让线上的业务不能持续进行。这是默认的淘汰策略
    * volatile-lru 尝试淘汰设置了过期时间的 key，最少使用的 key 优先被淘汰。没有设置过 期时间的 key 不会被淘汰，这样可以保证需要持久化的数据不会突然丢失。
    * volatile-ttl 跟上面一样，除了淘汰的策略不是 LRU，而是 key 的剩余寿命 ttl 的值，ttl 越小越优先被淘汰。
    * volatile-random 跟上面一样，不过淘汰的 key 是过期 key 集合中随机的 key。
    * allkeys-lru 区别于 volatile-lru，这个策略要淘汰的 key 对象是全体的 key 集合，而不 只是过期的 key 集合。这意味着没有设置过期时间的 key 也会被淘汰。
    * allkeys-random 跟上面一样，不过淘汰的策略是随机的 key。
  * volatile-xxx 策略只会针对带过期时间的 key 进行淘汰; allkeys-xxx 策略会对所有的 key 进行淘汰。
  * 如果你只是拿 Redis 做缓存，那应该使用 allkeys-xxx，客户端写缓存时 不必携带过期时间。如果你还想同时使用 Redis 的持久化功能，那就使用 volatile-xxx 策略，这样可以保留没有设置过期时间的 key，它们是永久的 key 不会被 LRU 算法淘 汰。
* 近似 LRU 算法
  * Redis 使用的是一种近似 LRU 算法，它跟 LRU 算法还不太一样。之所以不使用 LRU 算法，是因为需要消耗大量的额外的内存，需要对现有的数据结构进行较大的改造
    * 近似 LRU 算法则很简单，在现有数据结构的基础上使用随机采样法来淘汰元素，能达到和 LRU 算法非常近似的效果。Redis 为实现近似 LRU 算法，它给每个 key 增加了一个额外的小字 段，这个字段的长度是 24 个 bit，也就是最后一次被访问的时间戳。
    * 到处理 key 过期方式分为集中处理和懒惰处理, 但是 LRU 淘汰不一样，它的处理 方式只有懒惰处理。当 Redis 执行写操作时，发现内存超出 maxmemory，就会执行一次 LRU 淘汰算法。这个算法也很简单，就是随机采样出 5(可以配置) 个 key，然后淘汰掉最 旧的 key，如果淘汰后内存还是超出 maxmemory，那就继续随机采样淘汰，直到内存低于 maxmemory 为止
    * 如何采样就是看 maxmemory-policy 的配置，如果是 allkeys 就是从所有的 key 字典中 随机，如果是 volatile 就从带过期时间的 key 字典中随机。每次采样多少个 key 看的是 maxmemory\_samples 的配置，默认为 5
    * 淘汰池是一个数组，它的大小是 maxmemory\_samples，在每一次淘汰循环中，新随机出 来的 key 列表会和淘汰池中的 key 列表进行融合，淘汰掉最旧的一个 key 之后，保留剩余 较旧的 key 列表放入淘汰池中留待下一个循环

四: 拓展篇——平波缓进 —— 懒惰删除

一直以来我们认为 Redis 是单线程的，但是 Redis 内部实际上并不是只有一个主线程，它还有几个异步线程专门用来 处理一些耗时的操作

* Redis 为什么要懒惰删除(lazy free)？
  * 删除的 key 是一个非常大的对象，比如一个包含了千万元素的 hash，那么删 除操作就会导致单线程卡顿。 unlink 指令，它能对删除操作进行懒 处理，丢给后台线程来异步回收内存。 当 unlink 指令发出时，要删除的Key就再也无法被主线程中的其它指令访问到了.
  * flushdb 和 flushall 指令，用来清空数据库，这也是极其缓慢的操作, Redis 4.0 同样给这两个指令也带来了异步化，在指令后面增加 async.
  * 异步队列: 会将unlink的 key 的内存回收操作包装成一个任 务，塞进异步任务队列，后台线程会从这个异步队列中取任务。任务队列被主线程和异步线 程同时操作，所以必须是一个线程安全的队列. 但是 不是所有的 unlink 操作都会延后处理，如果对应 key 所占用的内存很小，延后处理就 没有必要了，这时候 Redis 会将对应的 key 内存立即回收，跟 del 指令一样
* AOF 也是异步任务
  * Redis 需要每秒一次(可配置)同步 AOF 日志到磁盘，确保消息尽量不丢失，需要调用 sync 函数，这个操作会比较耗时，会导致主线程的效率下降，所以 Redis 也将这个操作移到 异步线程来完成。执行 AOF Sync 操作的线程是一个独立的异步线程，和前面的懒惰删除线 程不是一个线程，同样它也有一个属于自己的任务队列，队列里只用来存放 AOF Sync 任务(和之前的惰性删除是 不同的线程, 不同的任务队列).

源码篇——简介

字符串 ------\> SDS(Simple Dynamic String)、long

字典 ------\> ziplist、HashTable(散列表)

set ------\> intset、HashTable(散列表, value都是null而已)

list ------\> LinkedList(quicklist)

zset ------\> ziplist、HashTable、SkipList(跳表)

* 字典转变
  * 当哈希对象可以同时满足以下两个条件时，哈希对象使用 ziplist 编码:
    * 哈希对象保存的所有键值对的键和值的字符串长度都小于64字节
    * 哈希对象保存的键值对数量小于512个
* 有序集合转变
  * 有序集合使用 ziplist 编码时，每个集合元素使用两个紧挨在一起的压缩列表节点表示，前一个节点是元素的值，第二个节点是元素的分值，也就是排序比较的数值。压缩列表内的集合元素按照分值从小到大进行排序。有序集合使用 skiplist 编码时使用 zset 结构作为底层实现，一个 zet 结构同时包含一个字典和一个跳跃表
  * 在如下两个条件之一满足的时候，ziplist会转成dict：
    * 当hash中的数据项（即field-value对）的数目超过512的时候，也就是ziplist数据项超过1024的时候
    * 当hash中插入的任意一个value的长度超过了64的时候。Redis的hash之所以这样设计，是因为当ziplist变得很大的时候，它有如下几个缺点：每次插入或修改引发的realloc操作会有更大的概率造成内存拷贝，从而降低性能。
    * 一旦发生内存拷贝，内存拷贝的成本也相应增加，因为要拷贝更大的一块数据。
    * 当ziplist数据项过多的时候，在它上面查找指定的数据项就会性能变得很低，因为ziplist上的查找需要进行遍历

源码篇——字符串

Redis 的字符串叫着「SDS」，也就是 Simple Dynamic String。它的结构是一个带长度信 息的字节数组.

C语言中想要获取一个字符串的长度的话, 需要进行遍历操作, 时间复杂度是O(n), Redis里面是O(1), 因为它就直接得保存了. 

struct SDS { 

 T capacity; // 数组容量 

 T len; // 数组长度 

 byte flags; // 特殊标识位，不理睬它 

 byte[] content; // 数组内容

}

Redis 规定字符串的长度不得超过 512M 字节。 Redis 的字符串有两种存储方式，在长度特别短时，使用 emb 形式存储 (embeded)，当 长度超过 44 时，使用 raw 形式存储.

字符串在长度小于 1M 之前，扩容空间采用加倍策略，也就是保留 100% 的冗余空 间。当长度超过 1M 之后，为了避免加倍后的冗余空间过大而导致浪费，每次扩容只会多分 配 1M 大小的冗余空间.

底层也可能是个long

下面来自于《Redis源码设计》

* SDS 代码结构
  * struct sdshdr{
    * int len; // 记录已使用长度
    * int free; // 记录空闲未使用的长度
    * char[] buf; // 字符数组
  * }
* SDS 动态扩展特点
  * 计算出大小是否足够
  * 开辟空间至满足所需大小
  * 开辟与已使用大小len相同长度的空闲free空间（如果len \< 1M）开辟1M长度的空闲free空间（如果len \>= 1M）
* Redis字符串的性能优势
  * 快速获取字符串长度
    * 在SDS里存了已使用字符长度len，所以当想获取字符串长度时直接返回len即可，时间复杂度为O(1)。如果使用C语言的字符串的话它的字符串长度获取函数时间复杂度为O(n),n为字符个数，因为他是从头到尾
  * 避免缓冲区溢出
    * 对一个C语言字符串进行strcat追加字符串的时候需要提前开辟需要的空间，如果不开辟空间的话可能会造成缓冲区溢出，而影响程序其他代码。如下图，有一个字符串s1="hello" 和 字符串s2="baby",现在要执行strcat(s1,"world"),并且执行前未给s1开辟空间，所以造成了缓冲区溢出。
  * 降低空间分配次数提升内存使用效率
    * 字符串的追加操作会涉及到内存分配问题，然而内存分配问题会牵扯内存划分算法以及系统调用所以如果频繁发生的话影响性能，所以对于性能至上的Redis来说这是万万不能忍受的。所以采取了一下两种优化措施
      * 空间与分配
        * 对于追加操作来说，Redis不仅会开辟空间至够用而且还会预分配未使用的空间(free)来用于下一次操作。至于未使用的空间(free)的大小则由修改后的字符串长度决定。
        * 当修改后的字符串长度len \< 1M,则会分配与len相同长度的未使用的空间(free)
        * 当修改后的字符串长度len \>= 1M,则会分配1M长度的未使用的空间(free)
        * 有了这个预分配策略之后会减少内存分配次数，因为分配之前会检查已有的free空间是否够，如果够则不开辟了～
      * 惰性空间回收
        * 与上面情况相反，惰性空间回收适用于字符串缩减操作。比如有个字符串s1="hello world"，对s1进行sdstrim(s1," world")操作，执行完该操作之后Redis不会立即回收减少的部分，而是会分配给下一个需要内存的程序。当然，Redis也提供了回收内存的api,可以自己手动调用来回收缩减部分的内存。

源码篇—— 字典

* 应用:
  * hash 结构的数据会用到 字典
  * 整个 Redis 数据库的所有 key 和 value 也组成了一个全局字典
  * 带过期时间 的 key 集合也是一个字典
  * zset 集合中存储 value 和 score 值的映射关系也是通过 dict 结构实现的
* 内部结构
  * 内部包含两个 hashtable，通常情况下只有一个 hashtable 是有值的。但是在 dict 扩容缩容时，需要分配新的 hashtable，然后进行渐进式搬迁，这时候两个 hashtable里面都有数据。待搬迁结束后，旧的 hashtable 被删除，新的 hashtable 取而代之。
  * 渐进式 rehash
    * 在字典很大时，rehash 是个耗时的操作，需要一次性全部 rehash。Redis 为了高性能，不能堵塞服务，所以采用了渐进式 rehash 策略。
    * 大字典的扩容是比较耗时间的，需要重新申请新的数组，然后将旧字典所有链表中的元 素重新挂接到新的数组下面，这是一个 O(n)级别的操作，作为单线程的 Redis 表示很难承受 这样耗时的过程。步子迈大了会扯着蛋，所以 Redis 使用渐进式 rehash 小步搬迁。虽然慢一 点，但是肯定可以搬完。在rehash时，会保留新旧两个 hash 结构，查询时会同时查询两个 hash 结构
  * 当 hash 移除了最后一个元素之后，该数据结构自动被删除，内存被回
  * Hash攻击
    * 如果 hash 函数存在偏向性，黑客就可能利用这种偏向性对服务器进行攻击。存在偏向性的 hash 函数在特定模式下的输入会导致 hash 第二维链表长度极为不均匀，甚至所有的 元素都集中到个别链表中，直接导致查找效率急剧下降，从 O(1)退化到 O(n)。有限的服务器计算能力将会被 hashtable 的查找效率彻底拖垮。这就是所谓 hash 攻击
  * 扩容条件
    * 正常情况下，当 hash 表中元素的个数等于第一维数组的长度时，就会开始扩容，扩容 的新数组是原数组大小的 2 倍。
    * 不过如果 Redis 正在做 bgsave，为了减少内存页的过多分离 (Copy On Write)，Redis 尽量不去扩容 (dict\_can\_resize)，
    * 但是如果 hash 表已经非常满 了，元素的个数已经达到了第一维数组长度的 5 倍 (dict\_force\_resize\_ratio)，说明 hash 表 已经过于拥挤了，这个时候就会强制扩容。
  * 缩容条件
    * 当 hash 表因为元素的逐渐删除变得越来越稀疏时，Redis 会对 hash 表进行缩容来减少 hash 表的第一维数组空间占用。
    * 缩容的条件是元素个数低于数组长度的 10%。
    * 缩容不会考 虑 Redis 是否正在做 bgsave
  * set 的结构
    * Redis 里面 set 的结构底层实现也是字典，只不过所有的 value 都是 NULL，其它的特 性和字典一模一样

源码篇—— 压缩列表

* 简介
  * 
  * Redis 为了节约内存空间使用，源码篇——快速列表

    * 简介
      * Redis 早期版本存储 list 列表数据结构使用的是压缩列表 ziplist 和普通的双向链表 linkedlist，也就是元素少时用 ziplist，元素多时用 linkedlist。
      * 考虑到链表的附加空间相对太高，prev 和 next 指针就要占去 16 个字节 (64bit 系统的 指针是 8 个字节)，另外每个节点的内存都是单独分配，会加剧内存的碎片化，影响内存管 理效率。后续版本对列表数据结构进行了改造，使用 quicklist 代替了 ziplist 和 linkedlist。
      * quicklist 是 ziplist 和 linkedlist 的混合体，它 将 linkedlist 按段切分，每一段使用 ziplist 来紧凑存储，多个 ziplist 之间使用双向指针串接起来
      * 为了进一步节约空间，Redis 还会对 ziplist 进行压缩存储，使用 LZF 算法压缩，可以选择压缩深度
      * quicklist 内部默认单个 ziplist 长度为 8k 字节，超出了这个字节数，就会新起一个 ziplist。ziplist 的长度由配置参数 list-max-ziplist-size 决定
      * quicklist 默认的压缩深度是 0，也就是不压缩。压缩的实际深度由配置参数 listcompress-depth 决定。为了支持快速的 push/pop 操作，quicklist 的首尾两个 ziplist 不压 缩

    跳跃列表

    * 跳表备注
      * 查找时间复杂度为O(logn)
      * 空间复杂度也是O(logn).
      * 假如一直往原始列表中添加数据, 但是不更新索引, 就可能出现两个索引节点之间数据非常多的情况, 极端情况, 跳表退化为单链表, 从而使得查找效率从 O(logn) 退化为 O(n).
    * 简介
      * Redis 的 zset 是一个复合结构，一方面它需要一个 hash 结构来存储 value 和 score 的 对应关系，另一方面需要提供按照 score 来排序的功能，还需要能够指定 score 的范围来获 取 value 列表的功能，这就需要另外一个结构「跳跃列表」
      * 查找
        * 如图所示，我们要定位到那个紫色的 kv，需要从 header 的最高层开始遍历找到第一个 节点 (最后一个比「我」小的元素)，然后从这个节点开始降一层再遍历找到第二个节点 (最 后一个比「我」小的元素)，然后一直降到最底层进行遍历就找到了期望的节点 (最底层的最 后一个比我「小」的元素)。其实也就是从Header最高层开始，找到最后一个比目标节点小的元素，然后将在这个节点上进行降级, 进行查找(因为这一级上的元素, 前面的肯定都比目标元素大了, 不降级的话你是找不到比目标元素小的那个的).
        * 
      * 随机层数
        * 对于每一个新插入的节点，都需要调用一个随机算法给它分配一个合理的层数。直观上 期望的目标是 50% 的 Level1，25% 的 Level2，12.5% 的 Level3，一直到最顶层 2^-63， 因为这里每一层的晋升概率是 50%[](resources/)然后就可以开始创建新 节点了，创建的时候需要给这个节点随机分配一个层数，再将搜索路径上的节点和这个新节点通过前向后向指针串起来。如果分配的新节点的高度高于当前跳跃列表的最大高度，就需 要更新一下跳跃列表的最大高度
      * 更新过程
        * 当我们调用 zadd 方法时，如果对应的 value 不存在，那就是插入过程。如果这个 value 已经存在了，只是调整一下 score 的值，那就需要走一个更新的流程。假设这个新的 score 值不会带来排序位置上的改变，那么就不需要调整位置，直接修改元素的 score 值就 可以了。但是如果排序位置改变了，那就要调整位置。那该如何调整位置呢？
          * 一个简单的策略就是先删除这个元素，再插入这个元素，需要经过两次路径搜索。Redis 就是这么干的。 不过 Redis 遇到 score 值改变了就直接删除再插入，不会去判断位置是否 需要调整，从这点看，Redis 的 zadd 的代码似乎还有优化空间
      * 如果 score 值都一样呢
        * 在一个极端的情况下，zset 中所有的 score 值都是一样的，zset 的查找性能会退化为 O(n) 么？所以 zset 的排序元素不只看 score 值，如果 score 值相同还需要再比较 value 值 (字符串比较)
      * 元素排名是怎么算出来的
        * Redis 在 skiplist 的 forward 指针上进行了优化，给每一个 forward 指针都增加了 span 属 性，span 是「跨度」的意思，表示从前一个节点沿着当前层的 forward 指针跳到当前这个节 点中间会跳过多少个节点。
        * 我们要计算一个元素的排名时，只需要将「搜索路径」上的经过的所有节点的跨 度 span 值进行叠加就可以算出元素的最终 rank 值

    源码篇——紧凑列表

    * 简介
      * Redis 5.0 又引入了一个新的数据结构 listpack，它是对 ziplist 结构的改进，在存储空间 上会更加节省，而且结构上也比 ziplist 要精简。
    * 它的整体形式和 ziplist 还是比较接近的。
      * listpack中的元素结构: 也就是entry, 不会存储上一个元素的长度, 而是存储当前元素的长度.
      * listpack去掉了zltail\_offset 字段, ziplist是利用它来定位最后一个元素进行从后向前的一个遍历操作. 但是listpack是根据 total\_bytes 和 最后一个元素的长度, 来计算最后一个的位置的. 所以这样的设计彻底消灭了ziplist 存在的级联更新行为，元素与元素之间完全独立，不会因为一个元素的长度变长就导致后续的元素内容会受到影响。
    * 取代 ziplist
      * listpack 的设计的目的是用来取代 ziplist，不过当下还没有做好替换 ziplist 的准备，因 为有很多兼容性的问题需要考虑，ziplist 在 Redis 数据结构中使用太广泛了，替换起来复杂 度会非常之高。它目前只使用在了新增加的 Stream 数据结构中

    源码篇——LFU

    * 简介
      * 全程是 least frequently used, 表示按最近的访问频率进行淘汰. 它比LRU更加精确的表示了一个Key被访问的热度.
        * 如果一个Key长时间不被访问, 然后突然被用户访问了一下, LRU算法下, 这个Key是不容易被淘汰的. 一个Key需要在一段时间内被访问多次, 才会被LFU认为, 它很热.
        * Redis所有对象头结构中都有一个 24bit的字段: lru.
          * LRU模式下, 它存储的是Redis的时钟: 就是Unix系统时间戳对2的24次方取模. 一个Key被访问一次, 这个值就被更新一次. 以此来计算一个Key的空闲时间. LRU算法就是靠比较对象的空闲时间来决定谁该被淘汰.
        * LFU
          * LFU模式下, lru字段用来存储两个值: 低8位存储访问频次(其实存储的是频次的对数值), 高16位存储上一次访问频次更新的时间.
          * 在内存满的时候会进行淘汰逻辑, 每次淘汰都是采用的随机策略. 随机挑选若干个Key, 更新下这个Key的热度. 淘汰掉热度比较低的.
          * LFU下, 访问次数的更新, 同LRU下一样, 也是在Key被访问时进行的. 但因为它存储的是访问次数的对数, 所以不能直接进行 +1 操作.
      * Redis 4.0 对淘汰策略增加了几种策略: volatile-lfu、allkeys-lfu.

    源码篇——再谈懒惰删除

    * 简介
      * 它使用异步线程对已删除的节点进行内存回收
    * 起初实现方案
      * 渐进式删除
        * 使用类似字典渐进式搬迁的方式来实现渐进式删除回收先删除二维的链表, 都删除之后，再删除一维的数组。
        * 问题：需要仔细控制回收频率。如果回收太猛，会导致CPU资源占用过多。回收太慢，可能会导致内存消耗持续增长。
    * 异步线程
      * 简单性
        * 不用为每一种数据结构都适配一套渐进式释放策略，也不用弄什么自适应算法仔细控制回收频率，只是将对象从全局字典中摘除掉，扔进队列中，然后主线程继续向下走，异步线程开始从队列中取数据，拿到之后同步释放即可。
      * 复杂性
        * Redis在之前，内部对象有共享机制。
        * 懒惰删除是彻底砍掉一个元素，将它扔到异步删除队列中去。但如果底层对象是共享的，那就做不到彻底删除。
        * Redis作者为了支持懒惰删除，将原有的对象共享机制彻底甩掉了。
      * 实现
        * 异步队列是用普通的双向链表来实现的，
        * Redis将删除操作的相关参数封装成一个 bio\_job结构，放到链表中，异步线程遍历链表，获取job元素再执行就可以了。
          * bio\_job 中主要有三个主要的参数: 这三个参数可以实现不同对象的删除逻辑.
            * arg1: 释放一个普通对象: string、set、zset、hash 等
            * arg2: 释放全局对象的dict字典和expires字典, 用于 flushdb等
            * arg3: 释放 Cluster 的slots\_to\_keys 对象.
      * 任务队列是一个不安全的双向链表，需要使用锁来保护。主线程追加任务时，需要先加锁，然后追加，再释放锁，如果异步线程在休眠的话，需要再唤醒异步线程。
      * 异步线程需要对任务队列进行轮询处理，一次从链表表头获取元素逐个处理。获取的时候也需要加锁，然后再解锁。 如果一个元素也没有，它需要等待，直到主线程来唤醒它。
      * 但是加锁是比较耗时的工作，尤其是悲观锁。如果删除很频繁的话，主线程就需要频繁的加锁和解锁。 你像 Java 的 ConcurrentLinkQueue 就没用这样粗粒度的锁，它使用CAS来控制并发。

    源码篇——深入字典遍历

    * 简介
      * Redis对象树的主干是一个字典，如果对象很多，这个主干字典也会很大。当我们使用keys命令搜寻指定的模式的key时，它会遍历整个主干字典。值得注意的是，在遍历过程中，如果满足条件的Key被找到了，还需要判断Key指向的对象是否已经过期，如果过期了，就需要从主干字典中将该key删除掉。
    * 问题
      * 字典在进行扩容时，使用的是渐进式rehash，会存在两个hashtable。遍历需要对这两个hashtable进行依次遍历，先遍历完旧的，再去遍历新的。如果遍历过程中发生了rehash，将已经遍历过的元素迁移到了新的hashtable中，那么遍历会不会出现重复的元素？
    * 迭代器的分类: Redis为字典的遍历提供了两种迭代器
      * 安全迭代器
        * 在遍历过程中可以对字典进行查找和修改，可以判断Key是否过期，过期的可以进行删除。
          * 在遍历时，会将当前元素和下一个元素一起放到迭代器中，防止安全迭代过程中，当前元素被删除后，找不到下一个元素。
        * 而且，在遍历过程中会禁止rehash，保证迭代过程中不会出现重复的元素。
          * 安全迭代器在开始迭代时，会给字典打一个标记，标识在此期间，禁止rehash操作。
      * 不安全迭代器
        * 在遍历过程中，字典是只读的，不可以修改。只能对字典进行遍历操作，不能调用任何触发过期判断的函数。
        * 好处是不影响rehash，代价就是遍历的元素可能会出现重复
      * 遍历完成后的操作
        * 安全第迭代器
          * 去掉字典的禁止rehash标记
        * 非安全迭代器
          * 检查指纹，Redis有个断言，就是指纹没有变化。如果有变动，服务器就会崩溃(failfast)
      * 指纹
        * 字典的指纹, 就是将字典的关键字段按位, 揉合到一起, 这样只要有任意的结构变动, 指纹都会发生变化. 如果只是元素的Value被修改了, 指纹不会变动.
    * 注意: 在字典扩容时进行的rehash操作, 将原数组中的链表迁移到新的数组中, 某个具体槽位的链表只可能会迁移到新数组的两个槽位中.(具体是一些位运算)
    * 迭代器的选择
      * 安全迭代器(简单来说, 只要你的遍历过程中不允许重复, 那就是用安全迭代器)
        * keys指令结果不允许重复
        * bgrewriteaof: 需要遍历所有的对象, 转换成指令进行持久化, 绝对不允许重复
        * bgsave: 也需要遍历所有对象来持久化, 同样不允许重复.
        * 另外, 如果迭代过程中需要处理元素的过期问题, 那也必须要使用安全迭代器. 因为 非安全迭代器是只读的.
      * 非安全迭代器
        * 其他情况, 也就是允许遍历过程中出现个别元素重复, 不需要对字典进行结构性修改的情况下, 一律使用非安全迭代器.
    * 注意: scan 命令用的是scan迭代器, 和这里的字典迭代器(安全/非安全迭代器)是两码事儿.